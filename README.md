# ee046211-deep-learning

<h1 align="center">
  <br>
MRI Brain Alzheimer Classification Under Advarsarial Attacks
  <br>
  <img src="assets/icons/mri_main_readme.jpg" height="300">
</h1>

<h4 align="center">
    Dor Lerman:
  
  <a href="https://www.linkedin.com/in/..."><img src="assets/icons/Linkedin_icon_readme.png" width="40" height="40"/></a>
    <a href="https://github.com/...."><img src="assets/icons/GitHub_icon_readme.png" width="40" height="40"/></a>
</a>

<h4 align="center">
    Niv Bar-Tov:
  
  <a href="https://www.linkedin.com/in/..."><img src="assets/icons/Linkedin_icon_readme.png" width="40" height="40"/></a>
    <a href="https://github.com/....."><img src="assets/icons/GitHub_icon_readme.png" width="40" height="40"/></a>
</a>

Alzhiemer classification task

<h4 align="center">
    <a href="https://colab.research.google.com/github/taldatech/ee046211-deep-learning"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
    <a href="https://nbviewer.jupyter.org/github/taldatech/ee046211-deep-learning/tree/main/"><img src="https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/nbviewer_badge.svg" alt="Open In NBViewer"/></a>
    <a href="https://mybinder.org/v2/gh/taldatech/ee046211-deep-learning/main"><img src="https://mybinder.org/badge_logo.svg" alt="Open In Binder"/></a>

</h4>
<p align="center">
    <a href="https://taldatech.github.io/ee046211-deep-learning/">Student Projects Website</a> â€¢ <a href="https://www.youtube.com/playlist?list=PLy3Xsl9jz-9WBHO850WFxv2TB5qtAlk0r">Video Tutorials (Winter 2024)</a>
  </p>


## Table of Contents

- [Project Overview](#project-overview)
- [Project Structure](#Project-Structure)
- [Installation](#installation)
- [Data](#data)
- [Model](#model)
- [Results](#results)
- [Usage](#usage)
- [Future Work](#future-work)
- [Sources and References](#sources-and-references)
- [License](#license)
- [Authors](#authors)


## Project Overview

## Project Structure
```
MRI_Brain_Alzheimer_Classification/
â”œâ”€â”€ ğŸ–¼ï¸ assets/
â”‚   â”œâ”€â”€ ğŸ” Dinov2/
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ loss_curve.png
â”‚   â”‚   â””â”€â”€ accuracy_curve.png
â”‚   â”œâ”€â”€ ğŸ” Dinov2_atk/
â”‚   â”‚   â”œâ”€â”€ ... 
â”‚   â”œâ”€â”€ ğŸ” Efficientnet/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ” Efficientnet_atk/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ” Restnet/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ ğŸ” Resnet_atk/
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ â›“ï¸ checkpoints/
â”‚   â”œâ”€â”€ ğŸ¯ optuna/
â”‚   â”‚   â”œâ”€â”€ Dinov2/
â”‚   â”‚   â”œâ”€â”€ Dinov2_atk/
â”‚   â”‚   â”œâ”€â”€ Efficientnet/
â”‚   â”‚   â”œâ”€â”€ Efficientnet_atk/
â”‚   â”‚   â”œâ”€â”€ Restnet/
â”‚   â”‚   â””â”€â”€ Resnet_atk/
â”‚   â”œâ”€â”€ Dinov2/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ Dinov2_atk/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ Efficientnet/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ Efficientnet_atk/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ Restnet/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ Resnet_atk/
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ ğŸ“Š dataset/
â”‚   â”œâ”€â”€ dataset_variables/
â”‚   â”‚   â”œâ”€â”€ train_set.pt
â”‚   â”‚   â”œâ”€â”€ validation_set.pt
â”‚   â”‚   â””â”€â”€ test_set.pt
â”‚   â”œâ”€â”€ raw_dataset/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â””â”€â”€ prepare_dataset.ipynb
â”œâ”€â”€ ğŸŒ env/
â”‚   â””â”€â”€ project_env.yaml
â”œâ”€â”€ ğŸ“š models/
â”‚   â”œâ”€â”€ results.ipynb
â”‚   â”œâ”€â”€ Dinov2.ipynb
â”‚   â”œâ”€â”€ Dinov2_atk.ipynb
â”‚   â”œâ”€â”€ Efficientnet.ipynb
â”‚   â”œâ”€â”€ Efficientnet_atk.ipynb
â”‚   â”œâ”€â”€ Restnet.ipynb
â”‚   â””â”€â”€ Resnet_atk.ipynb
â””â”€â”€ ğŸ› ï¸ utils/
    â”œâ”€â”€ optuna_search.py
    â”œâ”€â”€ utils_funcs.py
    â””â”€â”€ grad_cam.py
```


## Installation

This code works with any OS - linux or windows. To setup all the required dependencies plesae follow the instructions below:

#### Conda

[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html) (Recommended) - Clone this repository and then create and activate the **`env/project_env.yaml`** conda environment using the provided environment definition:

```
conda env create -f env/project_env.yaml
conda activate project_env
```

#### Pip Install

Clone this repository and then use the provided **`env/requirements.txt`** to install the dependencies.

```
pip install -r env/requirements.txt
```

## Data

Our project utilizes the [Best Alzheimer's MRI Dataset](https://www.kaggle.com/datasets/lukechugh/best-alzheimer-mri-dataset-99-accuracy), a comprehensive and curated collection of MRI scans specifically designed for Alzheimer's classification. This dataset serves as an improved version of the raw dataset available [here](https://www.kaggle.com/datasets/tourist55/alzheimers-dataset-4-class-of-images).

To address class imbalance, the dataset incorporates synthetic images generated through advanced techniques, ensuring a more balanced distribution of classes. The original real images have been allocated to the test directory for thorough evaluation.

All images have been resized to **224x224 pixels** to meet the input requirements of the deep learning models used in this project. The data is organized as follows:


A **`prepare_dataset.ipynb`** notebook located in the **`dataset`** directory is responsible for splitting the data into:

- **80%** for training
- **10%** for validation
- **10%** for testing

The data is structured as follows:

- **Training Set**: Contains both synthetic and real images, providing a balanced source for model training.
- **Validation Set**: Used for hyperparameter tuning and monitoring model performance during training to help prevent overfitting.
- **Test Set**: Comprises only real images for an unbiased final evaluation of the trained models.



## Sources and References
