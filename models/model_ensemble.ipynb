{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHRbRXSV2j50"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 35px\">\n",
        "    <img src=\"../assets/icons/icons8-clickteam-fusion-48.png\" style=\"width: 50px; height: 50px; margin-right: 10px;\">\n",
        "    <strong>MRI Brain Alzheimer Classification - Model Ensemble</strong>\n",
        "</h1>\n",
        "\n",
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY-DE_tE2j53"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-git-48.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Clone Repository from GitHub\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq1sKlsh2j54",
        "outputId": "d8697230-ca5b-4c9a-b105-c89f58d3cbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MRI_Brain_Alzheimer_Classification'...\n",
            "remote: Enumerating objects: 18614, done.\u001b[K\n",
            "remote: Counting objects: 100% (638/638), done.\u001b[K\n",
            "remote: Compressing objects: 100% (319/319), done.\u001b[K\n",
            "remote: Total 18614 (delta 315), reused 624 (delta 302), pack-reused 17976 (from 1)\u001b[K\n",
            "Receiving objects: 100% (18614/18614), 231.29 MiB | 16.76 MiB/s, done.\n",
            "Resolving deltas: 100% (391/391), done.\n",
            "Updating files: 100% (11597/11597), done.\n",
            "/content/MRI_Brain_Alzheimer_Classification\n"
          ]
        }
      ],
      "source": [
        "# Clone repository from GitHub\n",
        "!git clone https://github.com/nivbartov/MRI_Brain_Alzheimer_Classification\n",
        "\n",
        "%cd MRI_Brain_Alzheimer_Classification\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsCwDsTC2j55"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-import-64.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Import Packages\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zHJeVROc2j55"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from kornia import augmentation as K\n",
        "from kornia.augmentation import AugmentationSequential\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json\n",
        "import gc\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLSol97Y2j55"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-function-80.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Import Internal Functions\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9VOHiiup2j55"
      },
      "outputs": [],
      "source": [
        "from models import def_models\n",
        "from utils import utils_funcs\n",
        "from utils import optuna_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxknZw_e2j55",
        "outputId": "bd56d0f9-cb67-4f22-f0cd-0326c487d259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.cuda.is_available(): True\n",
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "utils_funcs.open_nvitop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKYbOvMs2j56"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-load-50.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Load Dataset\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HNgwMx612j56"
      },
      "outputs": [],
      "source": [
        "test_set = torch.load('dataset/dataset_variables/test_set.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouD3zpo_2j56"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-data-recovery-40.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Models Definition and Initialization\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oInSv-Pe2j56"
      },
      "source": [
        "**DINOv2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ZIZ_Gb2j56",
        "outputId": "49f6013a-5e60-4abf-d603-8f2df33b473d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize input and output sizes\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "input_channels = 3\n",
        "output_channels = 4\n",
        "\n",
        "dino_v2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "# Create DINOv2 model with FC layers before the output\n",
        "dino_v2_model = def_models.DINOv2(DINOv2_backbone=dino_v2_model, output_channels=output_channels).to(device)\n",
        "\n",
        "pretrained_model_path = f\"./checkpoints/DINOv2_atk_120234_12102024_train_0.2628_val_0.5694.pth\"\n",
        "checkpoint = torch.load(pretrained_model_path,weights_only=True)\n",
        "dino_v2_model.load_state_dict(checkpoint['net'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE-Y4wEi2j56"
      },
      "source": [
        "**EfficientnetB0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK1kffc52j56",
        "outputId": "4c0ecbbc-c4c2-4fa4-ad87-40985f9bf290"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize input and output sizes\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "input_channels = 3\n",
        "output_channels = 4\n",
        "\n",
        "# Load a pre-trained EfficientNet-B0 model\n",
        "EfficientNet_backbone_model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Freeze EfficientNet-B0 layers\n",
        "for param in EfficientNet_backbone_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Create EfficientNet-B0 model with FC layers before the output\n",
        "efficientnet_model = def_models.EfficientNet(EfficientNet_backbone=EfficientNet_backbone_model, output_channels=output_channels).to(device)\n",
        "\n",
        "pretrained_model_path = './checkpoints/EfficientNet_atk_110930_26102024_train_0.0037_val_0.0601.pth'\n",
        "checkpoint = torch.load(pretrained_model_path,weights_only=True)\n",
        "efficientnet_model.load_state_dict(checkpoint['net'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQYtN-mQ2j57"
      },
      "source": [
        "**Resnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWxAtfgT2j57",
        "outputId": "33139375-5d73-42df-c3a4-816ea8939b58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize input and output sizes\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "input_channels = 3\n",
        "output_channels = 4\n",
        "\n",
        "# Load a pre-trained ResNet34 model\n",
        "ResNet_backbone_model = torchvision.models.resnet34(pretrained=True)\n",
        "\n",
        "# Create ResNet34 model with FC layers before the output\n",
        "resnet_model = def_models.ResNet(ResNet_backbone=ResNet_backbone_model, output_channels=output_channels).to(device)\n",
        "\n",
        "pretrained_model_path = './checkpoints/ResNet_atk_091635_23102024_train_0.0092_val_0.0940.pth'\n",
        "checkpoint = torch.load(pretrained_model_path,weights_only=True)\n",
        "resnet_model.load_state_dict(checkpoint['net'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3eOcIl42j57"
      },
      "source": [
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-loader-80.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Create Data Loaders\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OZYXuqKV2j57"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLt4yu1K2j57"
      },
      "source": [
        "\n",
        "<h1 style=\"display: flex; align-items: center; font-size: 25px; margin: 0;\">\n",
        "    <img src=\"../assets/icons/icons8-unite-64.png\" style=\"width: 40px; height: 40px; margin-right: 5px;\">\n",
        "    Model Ensemble\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlFWGdPd2j57"
      },
      "source": [
        "**Define parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XUvZmtgb2j57"
      },
      "outputs": [],
      "source": [
        "# General parameters\n",
        "models_group = [dino_v2_model, resnet_model, efficientnet_model]\n",
        "weights = [0.43,0.25,0.32]\n",
        "\n",
        "# FGSM parameters\n",
        "epsilons = [0.005, 0.0005, 0.1, 0.2]\n",
        "\n",
        "# PGD parameters\n",
        "alphas = [0.0001, 0.001, 0.0001, 0.0001]\n",
        "num_iter = 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iWu3S2c2j57"
      },
      "source": [
        "**Make the Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO7Vqwgi2j58"
      },
      "source": [
        "**Natural Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeAanwuu2j58",
        "outputId": "e17dcfc5-7f16-48a4-c096-d4c9cffda65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Accuracy on Natural Images: 98.671%\n"
          ]
        }
      ],
      "source": [
        "ensemble_accuracy = utils_funcs.calculate_ensemble_accuracy(models_group, weights, testloader, device)\n",
        "print(\"Ensemble Model Accuracy on Natural Images: {:.3f}%\".format(ensemble_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa2OHAUX2j58"
      },
      "source": [
        "**Images Under FGSM Attack**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geCCUD-l2j58",
        "outputId": "20e68d03-4ac4-489f-eb9b-346ae4ca57ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Accuracy on FGSM with epsilon 0.005: 29.867%\n",
            "Ensemble Model Accuracy on FGSM with epsilon 0.0005: 92.025%\n",
            "Ensemble Model Accuracy on FGSM with epsilon 0.1: 28.616%\n",
            "Ensemble Model Accuracy on FGSM with epsilon 0.2: 11.337%\n"
          ]
        }
      ],
      "source": [
        "attack_type = 'fgsm'\n",
        "for epsilon in epsilons:\n",
        "  ensemble_atk_accuracy = utils_funcs.calculate_ensemble_atk_accuracy(models_group, weights, testloader, device, epsilon=epsilon, attack_type=attack_type)\n",
        "  print(f\"Ensemble Model Accuracy on FGSM with epsilon {epsilon}: {ensemble_atk_accuracy:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkp_ZUSz2j58"
      },
      "source": [
        "**Images Under PGD Attack**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JF1tQaR2j58",
        "outputId": "a9f84af9-1499-4f4c-ea58-ebf48a507855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Accuracy on PGD with epsilon 0.005 and alpha 0.0001: 91.009%\n",
            "Ensemble Model Accuracy on PGD with epsilon 0.0005 and alpha 0.001: 91.087%\n",
            "Ensemble Model Accuracy on PGD with epsilon 0.1 and alpha 0.0001: 89.992%\n",
            "Ensemble Model Accuracy on PGD with epsilon 0.2 and alpha 0.0001: 45.739%\n"
          ]
        }
      ],
      "source": [
        "attack_type = 'pgd'\n",
        "for epsilon, alpha in zip(epsilons, alphas):\n",
        "    ensemble_atk_accuracy = utils_funcs.calculate_ensemble_atk_accuracy(models_group, weights, testloader, device, epsilon=epsilon, alpha=alpha, attack_type='pgd', num_iter=num_iter)\n",
        "    print(f\"Ensemble Model Accuracy on PGD with epsilon {epsilon} and alpha {alpha}: {ensemble_atk_accuracy:.3f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dino_deep_learn_cuda124",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
