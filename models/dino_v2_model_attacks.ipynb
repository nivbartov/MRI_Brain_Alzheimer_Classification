{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSXDJcczMrB6"
      },
      "source": [
        "# **MRI Brain Alzheimer Classification - DINOv2 Model with Adversarial Attacks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Clone Dataset from GitHub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository from GitHub\n",
        "# !git clone https://github.com/nivbartov/MRI_Brain_Alzheimer_Classification\n",
        "\n",
        "# %cd MRI_Brain_Alzheimer_Classification\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from kornia import augmentation as K\n",
        "from kornia.augmentation import AugmentationSequential\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json\n",
        "import gc\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Internal Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import def_models\n",
        "from utils import utils_funcs\n",
        "from utils import optuna_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IptrfzT2UHGO"
      },
      "source": [
        "**Device Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOBQ7z2JUHGO"
      },
      "outputs": [],
      "source": [
        "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(torch.cuda.memory_summary())\n",
        "utils_funcs.open_nvitop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = torch.load('dataset/dataset_variables/train_set.pt')\n",
        "validation_set = torch.load('dataset/dataset_variables/validation_set.pt')\n",
        "test_set = torch.load('dataset/dataset_variables/test_set.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCYl_TtCNRRy"
      },
      "source": [
        "**Model Definition and Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0rr3nWPNoN8"
      },
      "outputs": [],
      "source": [
        "# Initialize input and output sizes\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "input_channels = 3\n",
        "output_channels = 4\n",
        "\n",
        "dino_v2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "# Freeze DINOv2 layers\n",
        "for param in dino_v2_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Create DINOv2 model with FC layers before the output\n",
        "model = def_models.DINO_v2_FT(dino_backbone=dino_v2_model, output_channels=output_channels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nMFF9zhUHGQ"
      },
      "source": [
        "**Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z1KwF9zUHGR"
      },
      "outputs": [],
      "source": [
        "# Resize images from 128x128 to 224x224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((input_height, input_width)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Apply transformation on the datasets\n",
        "train_set = utils_funcs.apply_transformations(train_set, transform)\n",
        "validation_set = utils_funcs.apply_transformations(validation_set, transform)\n",
        "test_set = utils_funcs.apply_transformations(test_set, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhIYASr5UHGR"
      },
      "source": [
        "**Model Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0UqlaFfUHGR"
      },
      "outputs": [],
      "source": [
        "model_name = type(model).__name__\n",
        "print(\"Model\", model_name, \"statistics:\")\n",
        "summary(model, (input_channels, input_height, input_width))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmuKR3cJUHGR"
      },
      "source": [
        "**Set Hyper-Parameters Using Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xIBs-LQUHGR"
      },
      "outputs": [],
      "source": [
        "load_existing_hyperparams = True\n",
        "\n",
        "if load_existing_hyperparams:\n",
        "    # Load hyper-parameters (relevant if optuna has already used)\n",
        "    optuna_params_path = f'./checkpoints/op_tuna_params/{model_name}/DINO_v2_FT_0.9109.json'\n",
        "    with open(optuna_params_path, 'r') as file:\n",
        "        hyperparams = json.load(file)\n",
        "else:\n",
        "    # Find optimal hyper-parameters using optuna\n",
        "    hyperparams = optuna_search.optuna_param_search(model_name=\"DINO_v2_FT\", loss_criterion=nn.CrossEntropyLoss(), num_epochs_for_experiments=10, device=device, transfer_learning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbernb7bUHGS"
      },
      "outputs": [],
      "source": [
        "# Set hyper-parameters\n",
        "batch_size = hyperparams['batch_size']\n",
        "learning_rate = hyperparams['lr']\n",
        "optimizer_name = hyperparams['optimizer']\n",
        "optimizer = getattr(torch.optim, optimizer_name)(model.fc.parameters(), lr=learning_rate)\n",
        "scheduler = hyperparams['scheduler']\n",
        "scheduler = StepLR(optimizer, 10, 0.1, verbose=True) if scheduler == \"StepLR\" else CosineAnnealingLR(optimizer, num_epochs, verbose=True)\n",
        "num_epochs = 50\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luwaRAYiUHGS"
      },
      "source": [
        "**Create Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEEfYQFTUHGT"
      },
      "outputs": [],
      "source": [
        "# Test loader witch batch size of 1 (in order to perform attacks one by one)\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=6, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWhJlALmW4vu"
      },
      "source": [
        "**Load Trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRblkHAlW2eN"
      },
      "outputs": [],
      "source": [
        "pretrained_model_path = f\"./checkpoints/{model_name}_074007_01102024.pth\"\n",
        "checkpoint = torch.load(pretrained_model_path,weights_only=True)\n",
        "last_epoch, last_loss = utils_funcs.load_model(model, optimizer, pretrained_model_path)\n",
        "model.load_state_dict(checkpoint['net'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CaKF7GCUHGT"
      },
      "source": [
        "**Perform Fast Gradient Sign (FGSM) Attack**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEZXyXHwUHGT"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "epsilons = [0, .0005, .005, .05, .1, .15, .2, .25, .3]\n",
        "\n",
        "for eps in epsilons:\n",
        "    acc, ex = utils_funcs.test_single_point_attack(model, device, testloader, 'fgsm', eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)\n",
        "\n",
        "utils_funcs.print_accuracy_table(epsilons, accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOsPbrZJUHGT"
      },
      "outputs": [],
      "source": [
        "utils_funcs.plot_adversarial_examples(epsilons, examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3YotQ8rUHGU"
      },
      "source": [
        "**Perform Projected Gradient Descent (PGD) Attack**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA4P-MVHUHGU"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "epsilons = [0, .0005, .005, .05, .1, .15, .2, .25, .3]\n",
        "alpha = 0.3\n",
        "num_iter = 5\n",
        "\n",
        "for eps in epsilons:\n",
        "    acc, ex = utils_funcs.test_single_point_attack(model, device, testloader, 'pgd', eps, alpha=alpha, num_iter=num_iter)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "utils_funcs.print_accuracy_table(epsilons, accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0LyHaLuUHGU"
      },
      "outputs": [],
      "source": [
        "utils_funcs.plot_adversarial_examples(epsilons, examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB_-dqsuUHGV"
      },
      "source": [
        "**Train Robust Model Against Adversarial Attacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bBOhoUnUHGW"
      },
      "outputs": [],
      "source": [
        "# Set hyper-parameters\n",
        "num_epochs = 2\n",
        "epsilon = 0.005\n",
        "adv_weight = 0.5\n",
        "\n",
        "# Combine train and validations sets for the full training\n",
        "full_train_set = ConcatDataset([train_set, validation_set])\n",
        "\n",
        "# Data loading and shuffling\n",
        "trainloader = torch.utils.data.DataLoader(full_train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdUFv85cUHGW"
      },
      "outputs": [],
      "source": [
        "epoch_losses = utils_funcs.adversarial_train(model, num_epochs, trainloader, device, criterion, optimizer, attack_type='fgsm', epsilon=epsilon, adv_weight=adv_weight, alpha=alpha, num_iter=num_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqYd2giKUHGX"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv2vYvOgUHGX"
      },
      "outputs": [],
      "source": [
        "test_accuracy = utils_funcs.calculate_accuracy(model, testloader, device)\n",
        "print(\"Test accuracy on regular test set: {:.3f}%\".format(test_accuracy))\n",
        "\n",
        "test_accuracy_adversial_attk = utils_funcs.calculate_accuracy_attack(model, testloader,device,attack_type='fgsm',epsilon=epsilon)\n",
        "print(\"Test accuracy on adversial attacks: {:.3f}%\".format(test_accuracy_adversial_attk))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyI2oBbRbS7Y"
      },
      "outputs": [],
      "source": [
        "class_names = ['VeryMildDemented', 'NonDemented', 'ModerateDemented', 'MildDemented']\n",
        "utils_funcs.plot_normalized_confusion_matrix(testloader, model, class_names, device, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ht9csMlUHGX"
      },
      "outputs": [],
      "source": [
        "utils_funcs.plot_loss_curve(epoch_losses, num_epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
