{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSXDJcczMrB6"
      },
      "source": [
        "# **MRI Brain Alzheimer Classification - DINOv2 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEWgxGwpIvtv"
      },
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_yU5PXHEX4x"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from kornia import augmentation as K\n",
        "from kornia.augmentation import AugmentationSequential\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mLsGXKEKVJy"
      },
      "source": [
        "**Clone Dataset from GitHub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuDq65E6UMbl"
      },
      "outputs": [],
      "source": [
        "# Clone repository from GitHub\n",
        "# !git clone https://github.com/nivbartov/MRI_Brain_Alzheimer_Classification\n",
        "\n",
        "# %cd MRI_Brain_Alzheimer_Classification\n",
        "%cd ..\n",
        "\n",
        "train_set = torch.load('dataset/dataset_variables/train_set.pt')\n",
        "validation_set = torch.load('dataset/dataset_variables/validation_set.pt')\n",
        "test_set = torch.load('dataset/dataset_variables/test_set.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Internal Functions**"
      ],
      "metadata": {
        "id": "vQJKfOGEJWan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import def_models\n",
        "from utils import utils_funcs\n",
        "from utils import optuna_search"
      ],
      "metadata": {
        "id": "clhd-UgNJb27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C9hi5C_-LDb"
      },
      "source": [
        "**Device Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gULVrEpb-LDb"
      },
      "outputs": [],
      "source": [
        "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCYl_TtCNRRy"
      },
      "source": [
        "**Model Definition and Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0rr3nWPNoN8"
      },
      "outputs": [],
      "source": [
        "# Initialize input and output sizes\n",
        "input_width = 224\n",
        "input_height = 224\n",
        "input_channels = 3\n",
        "output_channels = 4\n",
        "\n",
        "dino_v2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "# Freeze DINOv2 layers\n",
        "for param in dino_v2_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Create DINOv2 model with FC layers before the output\n",
        "model = def_models.DINO_v2_FT(dino_backbone=dino_v2_model, output_channels=output_channels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF84jpwS-LDd"
      },
      "source": [
        "**Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeIrRkHI-LDd"
      },
      "outputs": [],
      "source": [
        "# Resize images from 128x128 to 224x224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((input_height, input_width)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Apply transformation on the datasets\n",
        "train_set = utils_funcs.apply_transformations(train_set, transform)\n",
        "validation_set = utils_funcs.apply_transformations(validation_set, transform)\n",
        "test_set = utils_funcs.apply_transformations(test_set, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vkYHTm--LDe"
      },
      "source": [
        "**Model Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeoGhA5A-LDe"
      },
      "outputs": [],
      "source": [
        "model_name = type(model).__name__\n",
        "print(\"Model\", model_name, \"statistics:\")\n",
        "summary(model, (input_channels, input_height, input_width))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IgNxKOu-LDf"
      },
      "source": [
        "**Set Hyper-Parameters Using Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbHsApTN-LDf"
      },
      "outputs": [],
      "source": [
        "load_existing_hyperparams = True\n",
        "\n",
        "if load_existing_hyperparams:\n",
        "    # Load hyper-parameters (relevant if optuna has already used)\n",
        "    optuna_params_path = f'./checkpoints/op_tuna_params/{model_name}/DINO_v2_FT_0.9109.json'\n",
        "    with open(optuna_params_path, 'r') as file:\n",
        "        hyperparams = json.load(file)\n",
        "else:\n",
        "    # Find optimal hyper-parameters using optuna\n",
        "    hyperparams = optuna_search.optuna_param_search(model_name=\"DINO_v2_FT\", loss_criterion=nn.CrossEntropyLoss(), num_epochs_for_experiments=10, device=device, transfer_learning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZJ3eTYHNxv3"
      },
      "outputs": [],
      "source": [
        "# Set hyper-parameters\n",
        "batch_size = hyperparams['batch_size']\n",
        "learning_rate = hyperparams['lr']\n",
        "optimizer_name = hyperparams['optimizer']\n",
        "optimizer = getattr(torch.optim, optimizer_name)(model.fc.parameters(), lr=learning_rate)\n",
        "scheduler = hyperparams['scheduler']\n",
        "scheduler = StepLR(optimizer, 10, 0.1, verbose=True) if scheduler == \"StepLR\" else CosineAnnealingLR(optimizer, num_epochs, verbose=True)\n",
        "num_epochs = 50\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentations**"
      ],
      "metadata": {
        "id": "FqhovXlwErj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentations = K.AugmentationSequential(\n",
        "    K.RandomHorizontalFlip(p=0.1),\n",
        "    K.RandomVerticalFlip(p=0.1),\n",
        "    K.RandomRotation(degrees=10, p=0.1),\n",
        "    K.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05), p=0.1),\n",
        "    K.RandomBrightness(brightness=(0.8, 1.2), p=0.1),\n",
        "    K.RandomContrast(contrast=(0.8, 1.2), p=0.1),\n",
        "    K.RandomGamma(gamma=(0.9, 1.1), p=0.1),\n",
        "    K.RandomSharpness(p=0.1),\n",
        "    same_on_batch=False\n",
        ")"
      ],
      "metadata": {
        "id": "4F_MUSBBEwao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfXa0erP-LDh"
      },
      "source": [
        "**Create Data Loaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osh9hV7S-LDh"
      },
      "outputs": [],
      "source": [
        "# Combine train and validations sets for the full training\n",
        "full_train_set = ConcatDataset([train_set, validation_set])\n",
        "\n",
        "# Data loading and shuffling\n",
        "trainloader = torch.utils.data.DataLoader(full_train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NMxcWt8WBVl"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFzmKpCGODd8"
      },
      "outputs": [],
      "source": [
        "load_existing_params = True\n",
        "\n",
        "if load_existing_params:\n",
        "    model_path = './checkpoints/DINO_v2_FT_070051_02102024.pth'\n",
        "    checkpoint = torch.load(model_path, weights_only=True)\n",
        "    last_epoch, last_loss = utils_funcs.load_model(model, optimizer, model_path)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "else:\n",
        "    epoch_losses = utils_funcs.train(model, num_epochs, trainloader, device, criterion, optimizer, scheduler, augmentations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbJ0dBbeVkzF"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWniJm-0VgEz"
      },
      "outputs": [],
      "source": [
        "test_accuracy = utils_funcs.calculate_accuracy(model, testloader, device)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VSHJRpx-LDj"
      },
      "outputs": [],
      "source": [
        "class_names = ['VeryMildDemented', 'NonDemented', 'ModerateDemented', 'MildDemented']\n",
        "utils_funcs.plot_normalized_confusion_matrix(testloader, model, class_names, device, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7O4VexWVcyQ"
      },
      "outputs": [],
      "source": [
        "utils_funcs.plot_loss_curve(epoch_losses, num_epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}