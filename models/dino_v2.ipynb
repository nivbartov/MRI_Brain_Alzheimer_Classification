{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSXDJcczMrB6"
      },
      "source": [
        "# **MRI Brain Alzheimer Classification - Dino V2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS-LcsglIn5e"
      },
      "source": [
        "**Clone Dataset from GitHub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Dor\\TECHNION\\deep_learning\\Project\\MRI_Barin_Alzheimer_Classification\n"
          ]
        }
      ],
      "source": [
        "# Check if the directory exists and clone if it does not\n",
        "# !if [ ! -d \"MRI_Brain_Alzheimer_Classification\" ]; then git clone https://github.com/nivbartov/MRI_Brain_Alzheimer_Classification; fi\n",
        "\n",
        "# Change directory to the cloned repository\n",
        "# %cd MRI_Brain_Alzheimer_Classification\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Install Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gq0ikAVMMuUK"
      },
      "outputs": [],
      "source": [
        "# # !git clone https://github.com/facebookresearch/dinov2.git\n",
        "# !pip install --no-deps -r requirements.txt \n",
        "\n",
        "# !pip show xformers || pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip show torchvision || pip install torchvision\n",
        "# !pip show optuna || pip install optuna\n",
        "# !pip show tqdm || pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEWgxGwpIvtv"
      },
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_yU5PXHEX4x",
        "outputId": "d6964a73-4847-43ec-d164-e29b28e9b3a3"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "# Suppress user and future warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# imports\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from kornia import augmentation as K\n",
        "from kornia.augmentation import AugmentationSequential\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "# repository imports\n",
        "from models import def_models\n",
        "from utils import utils_funcs\n",
        "from utils import optuna_search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Device Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.cuda.is_available(): True\n",
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# check if there is a CUDA device available \n",
        "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
        "\n",
        "# device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mLsGXKEKVJy"
      },
      "source": [
        "**Load the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YuDq65E6UMbl"
      },
      "outputs": [],
      "source": [
        "train_set = torch.load('dataset/dataset_variables/train_set.pt')\n",
        "validation_set = torch.load('dataset/dataset_variables/validation_set.pt')\n",
        "test_set = torch.load('dataset/dataset_variables/test_set.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Pre-processing of the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resize images from 128x128 to 224x224 transformation\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), \n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Apply transformations to the datasets\n",
        "train_set = utils_funcs.apply_transformations(train_set, preprocess)\n",
        "validation_set = utils_funcs.apply_transformations(validation_set, preprocess)\n",
        "test_set = utils_funcs.apply_transformations(test_set, preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCYl_TtCNRRy"
      },
      "source": [
        "**Model Definition and Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h0rr3nWPNoN8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
          ]
        }
      ],
      "source": [
        "# Initialize in,out channels, width and height sizes\n",
        "input_channels = 3\n",
        "width = 224\n",
        "height = 224\n",
        "output_channels = 4\n",
        "\n",
        "dino_v2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "# freeze dino_v2 layers\n",
        "for param in dino_v2_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "\n",
        "# make the model\n",
        "model = def_models.DINO_v2_FT(dino_backbone=dino_v2_model, output_channels=output_channels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model  DINO_v2_FT  statistics\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 384, 16, 16]         226,176\n",
            "          Identity-2             [-1, 256, 384]               0\n",
            "        PatchEmbed-3             [-1, 256, 384]               0\n",
            "         LayerNorm-4             [-1, 257, 384]             768\n",
            "            Linear-5            [-1, 257, 1152]         443,520\n",
            "            Linear-6             [-1, 257, 384]         147,840\n",
            "           Dropout-7             [-1, 257, 384]               0\n",
            "   MemEffAttention-8             [-1, 257, 384]               0\n",
            "        LayerScale-9             [-1, 257, 384]               0\n",
            "        LayerNorm-10             [-1, 257, 384]             768\n",
            "           Linear-11            [-1, 257, 1536]         591,360\n",
            "             GELU-12            [-1, 257, 1536]               0\n",
            "          Dropout-13            [-1, 257, 1536]               0\n",
            "           Linear-14             [-1, 257, 384]         590,208\n",
            "          Dropout-15             [-1, 257, 384]               0\n",
            "              Mlp-16             [-1, 257, 384]               0\n",
            "       LayerScale-17             [-1, 257, 384]               0\n",
            "NestedTensorBlock-18             [-1, 257, 384]               0\n",
            "        LayerNorm-19             [-1, 257, 384]             768\n",
            "           Linear-20            [-1, 257, 1152]         443,520\n",
            "           Linear-21             [-1, 257, 384]         147,840\n",
            "          Dropout-22             [-1, 257, 384]               0\n",
            "  MemEffAttention-23             [-1, 257, 384]               0\n",
            "       LayerScale-24             [-1, 257, 384]               0\n",
            "        LayerNorm-25             [-1, 257, 384]             768\n",
            "           Linear-26            [-1, 257, 1536]         591,360\n",
            "             GELU-27            [-1, 257, 1536]               0\n",
            "          Dropout-28            [-1, 257, 1536]               0\n",
            "           Linear-29             [-1, 257, 384]         590,208\n",
            "          Dropout-30             [-1, 257, 384]               0\n",
            "              Mlp-31             [-1, 257, 384]               0\n",
            "       LayerScale-32             [-1, 257, 384]               0\n",
            "NestedTensorBlock-33             [-1, 257, 384]               0\n",
            "        LayerNorm-34             [-1, 257, 384]             768\n",
            "           Linear-35            [-1, 257, 1152]         443,520\n",
            "           Linear-36             [-1, 257, 384]         147,840\n",
            "          Dropout-37             [-1, 257, 384]               0\n",
            "  MemEffAttention-38             [-1, 257, 384]               0\n",
            "       LayerScale-39             [-1, 257, 384]               0\n",
            "        LayerNorm-40             [-1, 257, 384]             768\n",
            "           Linear-41            [-1, 257, 1536]         591,360\n",
            "             GELU-42            [-1, 257, 1536]               0\n",
            "          Dropout-43            [-1, 257, 1536]               0\n",
            "           Linear-44             [-1, 257, 384]         590,208\n",
            "          Dropout-45             [-1, 257, 384]               0\n",
            "              Mlp-46             [-1, 257, 384]               0\n",
            "       LayerScale-47             [-1, 257, 384]               0\n",
            "NestedTensorBlock-48             [-1, 257, 384]               0\n",
            "        LayerNorm-49             [-1, 257, 384]             768\n",
            "           Linear-50            [-1, 257, 1152]         443,520\n",
            "           Linear-51             [-1, 257, 384]         147,840\n",
            "          Dropout-52             [-1, 257, 384]               0\n",
            "  MemEffAttention-53             [-1, 257, 384]               0\n",
            "       LayerScale-54             [-1, 257, 384]               0\n",
            "        LayerNorm-55             [-1, 257, 384]             768\n",
            "           Linear-56            [-1, 257, 1536]         591,360\n",
            "             GELU-57            [-1, 257, 1536]               0\n",
            "          Dropout-58            [-1, 257, 1536]               0\n",
            "           Linear-59             [-1, 257, 384]         590,208\n",
            "          Dropout-60             [-1, 257, 384]               0\n",
            "              Mlp-61             [-1, 257, 384]               0\n",
            "       LayerScale-62             [-1, 257, 384]               0\n",
            "NestedTensorBlock-63             [-1, 257, 384]               0\n",
            "        LayerNorm-64             [-1, 257, 384]             768\n",
            "           Linear-65            [-1, 257, 1152]         443,520\n",
            "           Linear-66             [-1, 257, 384]         147,840\n",
            "          Dropout-67             [-1, 257, 384]               0\n",
            "  MemEffAttention-68             [-1, 257, 384]               0\n",
            "       LayerScale-69             [-1, 257, 384]               0\n",
            "        LayerNorm-70             [-1, 257, 384]             768\n",
            "           Linear-71            [-1, 257, 1536]         591,360\n",
            "             GELU-72            [-1, 257, 1536]               0\n",
            "          Dropout-73            [-1, 257, 1536]               0\n",
            "           Linear-74             [-1, 257, 384]         590,208\n",
            "          Dropout-75             [-1, 257, 384]               0\n",
            "              Mlp-76             [-1, 257, 384]               0\n",
            "       LayerScale-77             [-1, 257, 384]               0\n",
            "NestedTensorBlock-78             [-1, 257, 384]               0\n",
            "        LayerNorm-79             [-1, 257, 384]             768\n",
            "           Linear-80            [-1, 257, 1152]         443,520\n",
            "           Linear-81             [-1, 257, 384]         147,840\n",
            "          Dropout-82             [-1, 257, 384]               0\n",
            "  MemEffAttention-83             [-1, 257, 384]               0\n",
            "       LayerScale-84             [-1, 257, 384]               0\n",
            "        LayerNorm-85             [-1, 257, 384]             768\n",
            "           Linear-86            [-1, 257, 1536]         591,360\n",
            "             GELU-87            [-1, 257, 1536]               0\n",
            "          Dropout-88            [-1, 257, 1536]               0\n",
            "           Linear-89             [-1, 257, 384]         590,208\n",
            "          Dropout-90             [-1, 257, 384]               0\n",
            "              Mlp-91             [-1, 257, 384]               0\n",
            "       LayerScale-92             [-1, 257, 384]               0\n",
            "NestedTensorBlock-93             [-1, 257, 384]               0\n",
            "        LayerNorm-94             [-1, 257, 384]             768\n",
            "           Linear-95            [-1, 257, 1152]         443,520\n",
            "           Linear-96             [-1, 257, 384]         147,840\n",
            "          Dropout-97             [-1, 257, 384]               0\n",
            "  MemEffAttention-98             [-1, 257, 384]               0\n",
            "       LayerScale-99             [-1, 257, 384]               0\n",
            "       LayerNorm-100             [-1, 257, 384]             768\n",
            "          Linear-101            [-1, 257, 1536]         591,360\n",
            "            GELU-102            [-1, 257, 1536]               0\n",
            "         Dropout-103            [-1, 257, 1536]               0\n",
            "          Linear-104             [-1, 257, 384]         590,208\n",
            "         Dropout-105             [-1, 257, 384]               0\n",
            "             Mlp-106             [-1, 257, 384]               0\n",
            "      LayerScale-107             [-1, 257, 384]               0\n",
            "NestedTensorBlock-108             [-1, 257, 384]               0\n",
            "       LayerNorm-109             [-1, 257, 384]             768\n",
            "          Linear-110            [-1, 257, 1152]         443,520\n",
            "          Linear-111             [-1, 257, 384]         147,840\n",
            "         Dropout-112             [-1, 257, 384]               0\n",
            " MemEffAttention-113             [-1, 257, 384]               0\n",
            "      LayerScale-114             [-1, 257, 384]               0\n",
            "       LayerNorm-115             [-1, 257, 384]             768\n",
            "          Linear-116            [-1, 257, 1536]         591,360\n",
            "            GELU-117            [-1, 257, 1536]               0\n",
            "         Dropout-118            [-1, 257, 1536]               0\n",
            "          Linear-119             [-1, 257, 384]         590,208\n",
            "         Dropout-120             [-1, 257, 384]               0\n",
            "             Mlp-121             [-1, 257, 384]               0\n",
            "      LayerScale-122             [-1, 257, 384]               0\n",
            "NestedTensorBlock-123             [-1, 257, 384]               0\n",
            "       LayerNorm-124             [-1, 257, 384]             768\n",
            "          Linear-125            [-1, 257, 1152]         443,520\n",
            "          Linear-126             [-1, 257, 384]         147,840\n",
            "         Dropout-127             [-1, 257, 384]               0\n",
            " MemEffAttention-128             [-1, 257, 384]               0\n",
            "      LayerScale-129             [-1, 257, 384]               0\n",
            "       LayerNorm-130             [-1, 257, 384]             768\n",
            "          Linear-131            [-1, 257, 1536]         591,360\n",
            "            GELU-132            [-1, 257, 1536]               0\n",
            "         Dropout-133            [-1, 257, 1536]               0\n",
            "          Linear-134             [-1, 257, 384]         590,208\n",
            "         Dropout-135             [-1, 257, 384]               0\n",
            "             Mlp-136             [-1, 257, 384]               0\n",
            "      LayerScale-137             [-1, 257, 384]               0\n",
            "NestedTensorBlock-138             [-1, 257, 384]               0\n",
            "       LayerNorm-139             [-1, 257, 384]             768\n",
            "          Linear-140            [-1, 257, 1152]         443,520\n",
            "          Linear-141             [-1, 257, 384]         147,840\n",
            "         Dropout-142             [-1, 257, 384]               0\n",
            " MemEffAttention-143             [-1, 257, 384]               0\n",
            "      LayerScale-144             [-1, 257, 384]               0\n",
            "       LayerNorm-145             [-1, 257, 384]             768\n",
            "          Linear-146            [-1, 257, 1536]         591,360\n",
            "            GELU-147            [-1, 257, 1536]               0\n",
            "         Dropout-148            [-1, 257, 1536]               0\n",
            "          Linear-149             [-1, 257, 384]         590,208\n",
            "         Dropout-150             [-1, 257, 384]               0\n",
            "             Mlp-151             [-1, 257, 384]               0\n",
            "      LayerScale-152             [-1, 257, 384]               0\n",
            "NestedTensorBlock-153             [-1, 257, 384]               0\n",
            "       LayerNorm-154             [-1, 257, 384]             768\n",
            "          Linear-155            [-1, 257, 1152]         443,520\n",
            "          Linear-156             [-1, 257, 384]         147,840\n",
            "         Dropout-157             [-1, 257, 384]               0\n",
            " MemEffAttention-158             [-1, 257, 384]               0\n",
            "      LayerScale-159             [-1, 257, 384]               0\n",
            "       LayerNorm-160             [-1, 257, 384]             768\n",
            "          Linear-161            [-1, 257, 1536]         591,360\n",
            "            GELU-162            [-1, 257, 1536]               0\n",
            "         Dropout-163            [-1, 257, 1536]               0\n",
            "          Linear-164             [-1, 257, 384]         590,208\n",
            "         Dropout-165             [-1, 257, 384]               0\n",
            "             Mlp-166             [-1, 257, 384]               0\n",
            "      LayerScale-167             [-1, 257, 384]               0\n",
            "NestedTensorBlock-168             [-1, 257, 384]               0\n",
            "       LayerNorm-169             [-1, 257, 384]             768\n",
            "          Linear-170            [-1, 257, 1152]         443,520\n",
            "          Linear-171             [-1, 257, 384]         147,840\n",
            "         Dropout-172             [-1, 257, 384]               0\n",
            " MemEffAttention-173             [-1, 257, 384]               0\n",
            "      LayerScale-174             [-1, 257, 384]               0\n",
            "       LayerNorm-175             [-1, 257, 384]             768\n",
            "          Linear-176            [-1, 257, 1536]         591,360\n",
            "            GELU-177            [-1, 257, 1536]               0\n",
            "         Dropout-178            [-1, 257, 1536]               0\n",
            "          Linear-179             [-1, 257, 384]         590,208\n",
            "         Dropout-180             [-1, 257, 384]               0\n",
            "             Mlp-181             [-1, 257, 384]               0\n",
            "      LayerScale-182             [-1, 257, 384]               0\n",
            "NestedTensorBlock-183             [-1, 257, 384]               0\n",
            "       LayerNorm-184             [-1, 257, 384]             768\n",
            "        Identity-185                  [-1, 384]               0\n",
            "DinoVisionTransformer-186                  [-1, 384]               0\n",
            "          Linear-187                  [-1, 512]         197,120\n",
            "     BatchNorm1d-188                  [-1, 512]           1,024\n",
            "            GELU-189                  [-1, 512]               0\n",
            "         Dropout-190                  [-1, 512]               0\n",
            "          Linear-191                  [-1, 256]         131,328\n",
            "     BatchNorm1d-192                  [-1, 256]             512\n",
            "            GELU-193                  [-1, 256]               0\n",
            "         Dropout-194                  [-1, 256]               0\n",
            "          Linear-195                  [-1, 128]          32,896\n",
            "     BatchNorm1d-196                  [-1, 128]             256\n",
            "            GELU-197                  [-1, 128]               0\n",
            "         Dropout-198                  [-1, 128]               0\n",
            "          Linear-199                   [-1, 64]           8,256\n",
            "     BatchNorm1d-200                   [-1, 64]             128\n",
            "            GELU-201                   [-1, 64]               0\n",
            "         Dropout-202                   [-1, 64]               0\n",
            "          Linear-203                    [-1, 4]             260\n",
            "================================================================\n",
            "Total params: 21,892,292\n",
            "Trainable params: 371,780\n",
            "Non-trainable params: 21,520,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 237.95\n",
            "Params size (MB): 83.51\n",
            "Estimated Total Size (MB): 322.04\n",
            "----------------------------------------------------------------\n",
            "Total parameters: 22428356\n",
            "Trainable parameters: 371780\n"
          ]
        }
      ],
      "source": [
        "# model statistics\n",
        "print(\"model \", type(model).__name__,\" statistics\")\n",
        "summary(model, (input_channels, height, width))\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-09-29 22:28:43,966] A new study created in memory with name: mri-alzhimer-classification\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optuna is done on device: cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [13:09<00:00, 78.91s/it]\n",
            "[I 2024-09-29 22:42:11,814] Trial 0 finished with value: 0.7953125 and parameters: {'lr': 0.003364709702214566, 'optimizer': 'RMSprop', 'batch_size': 256}. Best is trial 0 with value: 0.7953125.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [15:55<00:00, 95.54s/it] \n",
            "[I 2024-09-29 22:58:24,599] Trial 1 finished with value: 0.8546875 and parameters: {'lr': 0.08340427009166704, 'optimizer': 'SGD', 'batch_size': 128}. Best is trial 1 with value: 0.8546875.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [20:55<00:00, 125.52s/it]\n",
            "[I 2024-09-29 23:19:34,555] Trial 2 finished with value: 0.8625 and parameters: {'lr': 0.01969347554219696, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 2 with value: 0.8625.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [08:57<00:00, 53.77s/it]\n",
            "[I 2024-09-29 23:28:45,814] Trial 3 finished with value: 0.7270833333333333 and parameters: {'lr': 0.018400606100817462, 'optimizer': 'SGD', 'batch_size': 32}. Best is trial 2 with value: 0.8625.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [08:33<00:00, 51.40s/it]\n",
            "[I 2024-09-29 23:37:33,774] Trial 4 finished with value: 0.5 and parameters: {'lr': 5.890676171928717e-06, 'optimizer': 'RMSprop', 'batch_size': 32}. Best is trial 2 with value: 0.8625.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:44<?, ?it/s]\n",
            "[I 2024-09-29 23:39:31,343] Trial 5 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:17<?, ?it/s]\n",
            "[I 2024-09-29 23:41:04,273] Trial 6 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:15<?, ?it/s]\n",
            "[I 2024-09-29 23:42:33,393] Trial 7 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:42<?, ?it/s]\n",
            "[I 2024-09-29 23:44:29,753] Trial 8 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [02:01<?, ?it/s]\n",
            "[I 2024-09-29 23:46:45,860] Trial 9 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 40%|████      | 4/10 [07:48<11:43, 117.19s/it]\n",
            "[I 2024-09-29 23:54:48,707] Trial 10 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [19:39<00:00, 117.93s/it]\n",
            "[I 2024-09-30 00:14:42,261] Trial 11 finished with value: 0.878125 and parameters: {'lr': 0.08614041554167083, 'optimizer': 'SGD', 'batch_size': 128}. Best is trial 11 with value: 0.878125.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [20:08<00:00, 120.87s/it]\n",
            "[I 2024-09-30 00:35:05,670] Trial 12 finished with value: 0.8578125 and parameters: {'lr': 0.0811229472494262, 'optimizer': 'SGD', 'batch_size': 128}. Best is trial 11 with value: 0.878125.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 50%|█████     | 5/10 [12:02<12:02, 144.49s/it]\n",
            "[I 2024-09-30 00:47:22,023] Trial 13 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [20:11<00:00, 121.17s/it]\n",
            "[I 2024-09-30 01:07:48,765] Trial 14 finished with value: 0.8578125 and parameters: {'lr': 0.0005794589868597246, 'optimizer': 'RMSprop', 'batch_size': 128}. Best is trial 11 with value: 0.878125.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:59<?, ?it/s]\n",
            "[I 2024-09-30 01:10:01,846] Trial 15 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:53<?, ?it/s]\n",
            "[I 2024-09-30 01:12:09,566] Trial 16 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 30%|███       | 3/10 [06:52<16:02, 137.47s/it]\n",
            "[I 2024-09-30 01:19:16,336] Trial 17 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [02:44<?, ?it/s]\n",
            "[I 2024-09-30 01:22:16,912] Trial 18 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [02:00<?, ?it/s]\n",
            "[I 2024-09-30 01:24:31,692] Trial 19 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:39<?, ?it/s]\n",
            "[I 2024-09-30 01:26:25,303] Trial 20 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 70%|███████   | 7/10 [16:31<07:04, 141.59s/it]\n",
            "[I 2024-09-30 01:43:10,814] Trial 21 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 40%|████      | 4/10 [09:51<14:46, 147.78s/it]\n",
            "[I 2024-09-30 01:53:16,215] Trial 22 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 40%|████      | 4/10 [09:51<14:47, 147.98s/it]\n",
            "[I 2024-09-30 02:03:22,559] Trial 23 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [02:20<?, ?it/s]\n",
            "[I 2024-09-30 02:05:57,638] Trial 24 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "100%|██████████| 10/10 [20:40<00:00, 124.00s/it]\n",
            "[I 2024-09-30 02:26:52,234] Trial 25 finished with value: 0.8921875 and parameters: {'lr': 0.0003168846480451579, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 25 with value: 0.8921875.\n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [02:10<?, ?it/s]\n",
            "[I 2024-09-30 02:29:18,248] Trial 26 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 20%|██        | 2/10 [04:53<19:32, 146.52s/it]\n",
            "[I 2024-09-30 02:34:26,205] Trial 27 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            "  0%|          | 0/10 [01:05<?, ?it/s]\n",
            "[I 2024-09-30 02:35:45,707] Trial 28 pruned. \n",
            "Using cache found in C:\\Users\\97252/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
            " 10%|█         | 1/10 [03:04<27:41, 184.61s/it]\n",
            "[I 2024-09-30 02:39:04,012] Trial 29 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  30\n",
            "  Number of pruned trials:  21\n",
            "  Number of complete trials:  9\n",
            "Best trial:\n",
            "  Value:  0.8921875\n",
            "  Params: \n",
            "    lr: 0.0003168846480451579\n",
            "    optimizer: Adam\n",
            "    batch_size: 128\n",
            "Best parameters saved to checkpoints/op_tuna_params\\DINO_v2_FT\\DINO_v2_FT_0.8922.json\n",
            "{'lr': 0.0003168846480451579, 'optimizer': 'Adam', 'batch_size': 128}\n"
          ]
        }
      ],
      "source": [
        "params = optuna_search.optuna_param_search(model_name=\"DINO_v2_FT\", loss_criterion=nn.CrossEntropyLoss(), num_epochs_for_experiments=10, device=device,transfer_learning=True)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEgWWGpPV8y-"
      },
      "source": [
        "**Hyper-Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zZJ3eTYHNxv3"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "batch_size = params['batch_size']\n",
        "learning_rate = params['lr']\n",
        "optimizer_name = params['optimizer']\n",
        "num_epochs = 50\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "##optimizer = getattr(torch.optim, optimizer_name)(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "optimizer = getattr(torch.optim, optimizer_name)(model.fc.parameters(), lr=learning_rate)\n",
        "\n",
        "# Combine train_set and val_set into one dataset and\n",
        "combined_train_val_set = ConcatDataset([train_set, validation_set])\n",
        "\n",
        "# Loading the data and shuffling it\n",
        "trainloader = torch.utils.data.DataLoader(combined_train_val_set, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=True)\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=6,pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NMxcWt8WBVl"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFzmKpCGODd8",
        "outputId": "54f07c21-de3e-4710-ae1b-f1cc12031b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model: DINO_v2_FT\n",
            "Epoch: 1 | Loss: 1.2004 | Training accuracy: 69.883% | Epoch Time: 280.63 secs\n",
            "Epoch: 2 | Loss: 0.8915 | Training accuracy: 79.805% | Epoch Time: 238.62 secs\n",
            "Epoch: 3 | Loss: 0.6835 | Training accuracy: 88.945% | Epoch Time: 277.74 secs\n",
            "Epoch: 4 | Loss: 0.5245 | Training accuracy: 92.754% | Epoch Time: 196.91 secs\n",
            "Epoch: 5 | Loss: 0.3800 | Training accuracy: 96.523% | Epoch Time: 233.98 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_025932_30092024.pth\n",
            "Epoch: 6 | Loss: 0.2850 | Training accuracy: 98.613% | Epoch Time: 277.94 secs\n",
            "Epoch: 7 | Loss: 0.2091 | Training accuracy: 98.457% | Epoch Time: 237.30 secs\n",
            "Epoch: 8 | Loss: 0.1605 | Training accuracy: 99.355% | Epoch Time: 219.55 secs\n",
            "Epoch: 9 | Loss: 0.1253 | Training accuracy: 99.629% | Epoch Time: 261.91 secs\n",
            "Epoch: 10 | Loss: 0.0994 | Training accuracy: 99.922% | Epoch Time: 220.75 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_031950_30092024.pth\n",
            "Epoch: 11 | Loss: 0.0876 | Training accuracy: 99.902% | Epoch Time: 214.19 secs\n",
            "Epoch: 12 | Loss: 0.0749 | Training accuracy: 99.961% | Epoch Time: 248.14 secs\n",
            "Epoch: 13 | Loss: 0.0683 | Training accuracy: 99.883% | Epoch Time: 235.30 secs\n",
            "Epoch: 14 | Loss: 0.0573 | Training accuracy: 99.961% | Epoch Time: 246.62 secs\n",
            "Epoch: 15 | Loss: 0.0515 | Training accuracy: 99.961% | Epoch Time: 230.15 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_033924_30092024.pth\n",
            "Epoch: 16 | Loss: 0.0480 | Training accuracy: 99.980% | Epoch Time: 240.31 secs\n",
            "Epoch: 17 | Loss: 0.0495 | Training accuracy: 99.902% | Epoch Time: 205.80 secs\n",
            "Epoch: 18 | Loss: 0.0366 | Training accuracy: 99.961% | Epoch Time: 339.32 secs\n",
            "Epoch: 19 | Loss: 0.0341 | Training accuracy: 99.961% | Epoch Time: 287.43 secs\n",
            "Epoch: 20 | Loss: 0.0271 | Training accuracy: 99.980% | Epoch Time: 229.53 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_040107_30092024.pth\n",
            "Epoch: 21 | Loss: 0.0270 | Training accuracy: 100.000% | Epoch Time: 234.56 secs\n",
            "Epoch: 22 | Loss: 0.0320 | Training accuracy: 99.980% | Epoch Time: 244.54 secs\n",
            "Epoch: 23 | Loss: 0.0310 | Training accuracy: 99.961% | Epoch Time: 237.99 secs\n",
            "Epoch: 24 | Loss: 0.0274 | Training accuracy: 100.000% | Epoch Time: 248.52 secs\n",
            "Epoch: 25 | Loss: 0.0213 | Training accuracy: 100.000% | Epoch Time: 229.28 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_042102_30092024.pth\n",
            "Epoch: 26 | Loss: 0.0267 | Training accuracy: 99.961% | Epoch Time: 244.25 secs\n",
            "Epoch: 27 | Loss: 0.0223 | Training accuracy: 99.980% | Epoch Time: 233.54 secs\n",
            "Epoch: 28 | Loss: 0.0222 | Training accuracy: 99.961% | Epoch Time: 209.77 secs\n",
            "Epoch: 29 | Loss: 0.0304 | Training accuracy: 99.863% | Epoch Time: 259.55 secs\n",
            "Epoch: 30 | Loss: 0.0337 | Training accuracy: 99.551% | Epoch Time: 194.50 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_044004_30092024.pth\n",
            "Epoch: 31 | Loss: 0.0283 | Training accuracy: 99.844% | Epoch Time: 245.78 secs\n",
            "Epoch: 32 | Loss: 0.0247 | Training accuracy: 99.961% | Epoch Time: 196.13 secs\n",
            "Epoch: 33 | Loss: 0.0248 | Training accuracy: 99.863% | Epoch Time: 241.01 secs\n",
            "Epoch: 34 | Loss: 0.0296 | Training accuracy: 99.961% | Epoch Time: 219.29 secs\n",
            "Epoch: 35 | Loss: 0.0191 | Training accuracy: 99.961% | Epoch Time: 249.72 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_045916_30092024.pth\n",
            "Epoch: 36 | Loss: 0.0187 | Training accuracy: 99.922% | Epoch Time: 211.97 secs\n",
            "Epoch: 37 | Loss: 0.0252 | Training accuracy: 99.785% | Epoch Time: 230.75 secs\n",
            "Epoch: 38 | Loss: 0.0194 | Training accuracy: 99.961% | Epoch Time: 221.64 secs\n",
            "Epoch: 39 | Loss: 0.0168 | Training accuracy: 99.883% | Epoch Time: 260.46 secs\n",
            "Epoch: 40 | Loss: 0.0112 | Training accuracy: 99.980% | Epoch Time: 225.32 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_051826_30092024.pth\n",
            "Epoch: 41 | Loss: 0.0156 | Training accuracy: 100.000% | Epoch Time: 264.79 secs\n",
            "Epoch: 42 | Loss: 0.0119 | Training accuracy: 99.980% | Epoch Time: 182.03 secs\n",
            "Epoch: 43 | Loss: 0.0171 | Training accuracy: 100.000% | Epoch Time: 286.06 secs\n",
            "Epoch: 44 | Loss: 0.0121 | Training accuracy: 100.000% | Epoch Time: 231.97 secs\n",
            "Epoch: 45 | Loss: 0.0127 | Training accuracy: 99.824% | Epoch Time: 221.92 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_053813_30092024.pth\n",
            "Epoch: 46 | Loss: 0.0154 | Training accuracy: 99.941% | Epoch Time: 234.59 secs\n",
            "Epoch: 47 | Loss: 0.0133 | Training accuracy: 99.961% | Epoch Time: 255.22 secs\n",
            "Epoch: 48 | Loss: 0.0143 | Training accuracy: 99.961% | Epoch Time: 210.65 secs\n",
            "Epoch: 49 | Loss: 0.0128 | Training accuracy: 99.961% | Epoch Time: 242.32 secs\n",
            "Epoch: 50 | Loss: 0.0102 | Training accuracy: 99.961% | Epoch Time: 219.64 secs\n",
            "==> Saving model ...\n",
            "saved as ./checkpoints/DINO_v2_FT_055736_30092024.pth\n"
          ]
        }
      ],
      "source": [
        "epoch_losses = utils_funcs.train(model, num_epochs, trainloader, device, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load fine-tuned parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_path = './checkpoints/DINO_v2_FT_20240929_163744.pth'\n",
        "# checkpoint = torch.load(model_path,weights_only=True)\n",
        "# last_epoch, last_loss = utils_funcs.load_model(model, optimizer, model_path)\n",
        "# model.load_state_dict(checkpoint['net'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbJ0dBbeVkzF"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "g7O4VexWVcyQ",
        "outputId": "31a8ce59-8229-46e2-fdbd-8b0233f20aec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "utils_funcs.plot_loss_curve(epoch_losses, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWniJm-0VgEz",
        "outputId": "ce9017cc-6400-41c3-da40-610bb1516ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 92.344%\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = utils_funcs.calculate_accuracy(model, testloader, device)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
